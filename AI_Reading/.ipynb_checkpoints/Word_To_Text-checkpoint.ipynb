{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBsYzbVZkw4i",
    "outputId": "a7f99195-8bd3-441d-d9b8-9a346632e3ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # SOS 와 EOS 포함\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "#/content/Data.xlsx\n",
    "def get_max_len(pairs):\n",
    "  data = np.array(pairs)\n",
    "  word_data = data[:,1]\n",
    "  text_data = data[:,0]\n",
    "\n",
    "  text = []\n",
    "  word = []\n",
    "\n",
    "  for i in range(len(data)):\n",
    "    text.append(word_tokenize(text_data[i]))\n",
    "    word.append(word_tokenize(word_data[i]))\n",
    "  text_max_len = max(len(item) for item in text)\n",
    "  word_max_len = max(len(item) for item in word)\n",
    "  print(f'text_max_len = {text_max_len}\\nword_max_len = {word_max_len}')\n",
    "  return word_max_len, text_max_len\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False, data = list):\n",
    "    print(\"Reading lines...\") \n",
    "    data = data.values\n",
    "\n",
    "    Non_norm_pairs = [[s for s in l] for l in data]\n",
    "    # 모든 줄을 쌍으로 분리하고 정규화\n",
    "    pairs = [[normalizeString(s) for s in l] for l in data]\n",
    "\n",
    "    # 쌍을 뒤집고, Lang 인스턴스 생성\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs, Non_norm_pairs\n",
    "\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False,data = list):\n",
    "    input_lang, output_lang, pairs, non_pairs = readLangs(lang1, lang2, reverse, data)\n",
    "    print(\"++++++++++readLANGS++++++++\",pairs)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    #pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[1])\n",
    "        output_lang.addSentence(pair[0])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    #print(\"find_max_pairlen(pairs)\",find_max_pairlen(pairs))\n",
    "    #print(pairs)\n",
    "    return input_lang, output_lang, pairs, non_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8MbI7wb7gwJi"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#input size == 8\n",
    "#output size = 32\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=int):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[1])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[0])\n",
    "    return (input_tensor, target_tensor)\n",
    "# text_max_len = 31\n",
    "# word_max_len = 6\n",
    "#이부분 max_length 구할 수 있도록 코드 작성하기(숙제! 내일까지!)\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=int):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing 포함: 목표를 다음 입력으로 전달\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # 입력으로 사용할 부분을 히스토리에서 분리\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01,max_length = int):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # print_every 마다 초기화\n",
    "    plot_loss_total = 0  # plot_every 마다 초기화\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion,max_length= max_length)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # 주기적인 간격에 이 locator가 tick을 설정\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=int):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "\n",
    "        #print('>', pair[0])\n",
    "        #print('=', pair[1])\n",
    "        print(\"입력 단어\",pair[1])\n",
    "        print(\"정답 문장\",pair[0])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[1])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print(\"예측 문장\", output_sentence)\n",
    "        #print('<', output_sentence)\n",
    "        #print('')\n",
    "\n",
    "def evaluateUsers(encoder, decoder):\n",
    "  words= ''\n",
    "  words =input()\n",
    "  print(\"입력 단어\",words)\n",
    "  output_words, attentions = evaluate(encoder, decoder,words)\n",
    "  output_sentence = ' '.join(output_words)\n",
    "  print(\"예측 문장\", output_sentence)\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "gNbdhD_B0nVn",
    "outputId": "f37325ec-b249-4315-c636-146263dff7bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A queen sat at a window.</td>\n",
       "      <td>queen, window, sit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A queen had a wonderful looking-glass.</td>\n",
       "      <td>queen, looking-glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When the queen stood in front of looking-glass...</td>\n",
       "      <td>queen, looking-glass, say, fairest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence                                Word\n",
       "0                           A queen sat at a window.                  queen, window, sit\n",
       "1             A queen had a wonderful looking-glass.                queen, looking-glass\n",
       "2  When the queen stood in front of looking-glass...  queen, looking-glass, say, fairest"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('/content/Data2.xlsx')\n",
    "data = data[data.columns[:2]][:-1]\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdBdu7v24UzQ",
    "outputId": "4203eaef-1aa7-489f-ecf4-4dc0f5e58f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "++++++++++readLANGS++++++++ [['a queen sat at a window .', 'queen window sit'], ['a queen had a wonderful looking glass .', 'queen looking glass'], ['when the queen stood in front of looking glass and looked at herself in it and said looking glass looking glass who in this land is the fairest of all . ', 'queen looking glass say fairest'], ['the looking glass answered queen you the fairest of all . ', 'looking glass answer fairest'], ['snow white was talking with animal friends .', 'snow white talk animal'], ['but now the poor snow white was all alone in the great forest .', 'snow white forest'], ['show white ran as long as her feet would go until it was almost evening then she saw a little cottage and went into it to rest herself .', 'snow white run cottage rest'], ['little snow white was so hungry and thirsty that she ate some vegetables and bread from plate and drank water out of mug .', 'snow white hungry thirsty ate vegetables bread plate mug water'], ['as snow white was so tired she laid herself down on one of the little beds and went to sleep .', 'snow white tired lay bed sleep'], ['when it was morning little snow white awoke and was frightened when she saw the seven dwarfs .', 'morning snow white awoke frightened seven dwarfs'], ['but the seven dwarfs were friendly and asked her what her name was . my name is snow white she answered .', 'seven dwarfs snow white name ask answer'], ['the queen went into a quite secret lonely room where no one ever came and there she made a very poisonous apple .', 'queen secret room made apple'], ['snow white had a bit of apple then she fell down .', 'snow white bit apple'], ['it happened however that a prince came into the forest . and he saw the coffin that laying the snow white .', 'prince forest saw show white coffin'], ['finally the snow white woke up and she married the prince .', 'snow white marry prince'], ['the little red riding hood is walking in the forest .', 'red riding hood walk forest'], ['little red riding hood set out immediately to go to her grandmother who lived in another village .', 'red riding hood set out grandmother village'], ['little red riding hood met with a wolf in forest . and the wolf asked little red riding hood where are you going .', 'red riding hood wolf met forest'], ['the little red riding hood was entertaining by gathering nuts running after butterflies and gathering bouquets of little flowers .', 'red riding hood entertain butterflies flower'], ['it was not long before the wolf arrived at the grandmother s house and knocked at the door .', 'wolf arrive house knock door'], ['the wolf opened the door and then he immediately ate the good grandmother up in a moment . because it been more than three days since wolf had eaten meals .', 'wolf open door ate grandmother'], ['the little red riding hood arrived grandmother s house and met the wolf who laid on bed wearing grandmother s nightclothes .', 'red riding hood arrive house grandmother met wolf bed grandmothers s nightclothes'], [' grandmother why you have got big teeth ? because of for will be eating you . saying these words this wicked wolf ate little red riding hood .', 'big teeth wolf ate red riding hood'], ['a hunter passing by found a wolf resting because he was full . inside the wolf s stomach hunter heard a voice asking for the help of grandmother and the red riding hood .', 'hunter pass wolf rest stomach voice'], ['the hunter split the wolf s belly and took out the red riding hood and grandmother . and put a stone in wolf s stomach and had tied it again .', 'red riding hood grandmother put stone wolf s stomach'], ['the wolf whose stomach was heavy because of the stone fell into a well while drinking water .', 'stomach heavy stone well drink water']]\n",
      "Read 26 sentence pairs\n",
      "Trimmed to 26 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "word 79\n",
      "text 204\n",
      "text_max_len = 35\n",
      "word_max_len = 16\n",
      "[' grandmother why you have got big teeth ? because of for will be eating you . saying these words this wicked wolf ate little red riding hood .', 'big teeth wolf ate red riding hood']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs,non_norm_pairs = prepareData('word', 'text', False, data)\n",
    "input_max_len, output_max_len = get_max_len(non_norm_pairs)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uz0fnyNqvVev",
    "outputId": "014cb1e8-55a1-4c79-b011-26020144d2a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 4s (- 1m 26s) (100 5%) 3.4254\n",
      "0m 8s (- 1m 16s) (200 10%) 2.9585\n",
      "0m 12s (- 1m 12s) (300 15%) 3.0051\n",
      "0m 17s (- 1m 8s) (400 20%) 2.7876\n",
      "0m 21s (- 1m 3s) (500 25%) 2.4224\n",
      "0m 25s (- 1m 0s) (600 30%) 2.2322\n",
      "0m 30s (- 0m 57s) (700 35%) 1.7656\n",
      "0m 35s (- 0m 53s) (800 40%) 1.2436\n",
      "0m 40s (- 0m 49s) (900 45%) 1.0045\n",
      "0m 45s (- 0m 45s) (1000 50%) 1.0458\n",
      "0m 50s (- 0m 41s) (1100 55%) 0.4488\n",
      "0m 56s (- 0m 37s) (1200 60%) 0.2951\n",
      "1m 1s (- 0m 33s) (1300 65%) 0.1560\n",
      "1m 6s (- 0m 28s) (1400 70%) 0.0621\n",
      "1m 12s (- 0m 24s) (1500 75%) 0.0426\n",
      "1m 17s (- 0m 19s) (1600 80%) 0.0373\n",
      "1m 23s (- 0m 14s) (1700 85%) 0.0295\n",
      "1m 28s (- 0m 9s) (1800 90%) 0.0251\n",
      "1m 34s (- 0m 4s) (1900 95%) 0.0220\n",
      "1m 39s (- 0m 0s) (2000 100%) 0.0190\n",
      "Train End\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1,max_length=output_max_len).to(device)\n",
    "\n",
    "#trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
    "trainIters(encoder1, attn_decoder1, n_iters = 2000, print_every=100,max_length = output_max_len)\n",
    "print('Train End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzc9jmaI0VSf",
    "outputId": "8710732b-08db-45c8-893d-78e5fd05074e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red queen riding hood bed stone\n",
      "입력 단어 red queen riding hood bed stone\n",
      "예측 문장 the little red riding hood was entertaining by gathering nuts running after butterflies and gathering bouquets of little flowers . <EOS>\n"
     ]
    }
   ],
   "source": [
    "evaluateUsers(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5o2JFuS00ar"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TextGenerator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
